{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 03 \u2014 Model Training & Evaluation\n",
        "\n",
        "This notebook trains two classifiers on the YAMNet embeddings produced in Notebook 02:\n",
        "1. A lightweight TensorFlow Keras DNN (easy to convert to TFLite)\n",
        "2. An XGBoost classifier (strong baseline)\n",
        "\n",
        "It computes Accuracy, Confusion Matrix, ROC & AUC, Precision/Recall, and saves the best models.\n",
        "\n",
        "**Inputs required**:\n",
        "- `metadata/features_manifest.json` (created by Notebook 02)\n",
        "- `data/features/*.npy` (embeddings)\n",
        "\n",
        "Run this in Google Colab (recommended) or locally.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Install dependencies (run once in Colab)\n",
        "!pip install --quiet tensorflow scikit-learn xgboost matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import joblib\n",
        "\n",
        "ROOT = Path('.')\n",
        "FEATURES_MANIFEST = ROOT / 'metadata' / 'features_manifest.json'\n",
        "MODEL_DIR = ROOT / 'models'\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with open(FEATURES_MANIFEST, 'r') as f:\n",
        "    manifest = json.load(f)\n",
        "\n",
        "print('Loaded manifest entries:', len(manifest))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Load features and labels\n",
        "X = []\n",
        "y = []\n",
        "speaker_ids = []\n",
        "for item in manifest:\n",
        "    emb_path = item['feature_path']\n",
        "    if not Path(emb_path).exists():\n",
        "        print('Missing emb:', emb_path)\n",
        "        continue\n",
        "    emb = np.load(emb_path)\n",
        "    X.append(emb)\n",
        "    label = 1 if item['label']=='familiar' else 0\n",
        "    y.append(label)\n",
        "    speaker_ids.append(item.get('speaker_id'))\n",
        "\n",
        "X = np.stack(X)\n",
        "y = np.array(y)\n",
        "print('Features shape', X.shape, 'Labels shape', y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Train/Val/Test split\n",
        "X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=42)\n",
        "print('Train', X_train.shape, 'Val', X_val.shape, 'Test', X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A) Keras DNN classifier\n",
        "Lightweight architecture that is easy to convert to TF-Lite for Android deployment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models, optimizers, callbacks\n",
        "\n",
        "def build_dnn(input_dim=1024):\n",
        "    inp = layers.Input(shape=(input_dim,))\n",
        "    x = layers.Dense(256, activation='relu')(inp)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    out = layers.Dense(1, activation='sigmoid')(x)\n",
        "    model = models.Model(inp, out)\n",
        "    model.compile(optimizer=optimizers.Adam(1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "dnn = build_dnn(X_train.shape[1])\n",
        "dnn.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "es = callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
        "mc = callbacks.ModelCheckpoint(str(MODEL_DIR / 'dnn_best.h5'), monitor='val_loss', save_best_only=True)\n",
        "\n",
        "history = dnn.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[es, mc])\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.title('DNN Loss')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Evaluate DNN on test set\n",
        "dnn_preds = dnn.predict(X_test).ravel()\n",
        "dnn_pred_labels = (dnn_preds >= 0.5).astype(int)\n",
        "print('DNN Accuracy:', accuracy_score(y_test, dnn_pred_labels))\n",
        "print('DNN ROC AUC:', roc_auc_score(y_test, dnn_preds))\n",
        "print(classification_report(y_test, dnn_pred_labels))\n",
        "cm = confusion_matrix(y_test, dnn_pred_labels)\n",
        "sns.heatmap(cm, annot=True, fmt='d')\n",
        "plt.title('DNN Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B) XGBoost classifier\n",
        "A strong tree-based baseline. We'll train and compare.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "xgb_preds = xgb_clf.predict_proba(X_test)[:,1]\n",
        "xgb_labels = (xgb_preds >= 0.5).astype(int)\n",
        "print('XGBoost Accuracy:', accuracy_score(y_test, xgb_labels))\n",
        "print('XGBoost ROC AUC:', roc_auc_score(y_test, xgb_preds))\n",
        "print(classification_report(y_test, xgb_labels))\n",
        "cm2 = confusion_matrix(y_test, xgb_labels)\n",
        "sns.heatmap(cm2, annot=True, fmt='d')\n",
        "plt.title('XGBoost Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Save models\n",
        "dnn.save(str(MODEL_DIR / 'dnn_final'))\n",
        "joblib.dump(xgb_clf, str(MODEL_DIR / 'xgb_final.joblib'))\n",
        "print('Saved DNN and XGBoost models to', MODEL_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Optional: export DNN to TensorFlow Lite for Android\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(str(MODEL_DIR / 'dnn_final'))\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "open(str(MODEL_DIR / 'dnn.tflite'), 'wb').write(tflite_model)\n",
        "print('Saved TFLite model:', MODEL_DIR / 'dnn.tflite')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next steps\n",
        "- Tune thresholds, collect more in-domain (Indian accent) data, and consider metric learning (AM-Softmax, triplet loss) for improved embeddings.\n",
        "- Integrate model into backend for real-time verification and Android client using TFLite.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}