{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ayush-1204/Speaker_Recognition_System/blob/main/notebooks/01_data_preparation.ipynb)\n",
    "\n",
    "# Notebook 01 — Data Preparation & VAD\n",
    "✅ Use this notebook for dataset creation and segmentation via VAD\n",
    "✅ Runs on Google Colab or local Jupyter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# You should install these once in Colab\n",
        "!pip install numpy scipy soundfile webrtcvad librosa sounddevice\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, json\n",
        "from pathlib import Path\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import webrtcvad\n",
        "from scipy.signal import resample_poly\n",
        "\n",
        "# Folder Setup\n",
        "ROOT = Path('.')\n",
        "DATA_RAW = ROOT / 'data/raw'\n",
        "DATA_PROCESSED = ROOT / 'data/processed'\n",
        "FAMILIAR_DIR = DATA_PROCESSED / 'familiar'\n",
        "STRANGER_DIR = DATA_PROCESSED / 'stranger'\n",
        "METADATA_DIR = ROOT / 'metadata'\n",
        "ENROLL_DB = METADATA_DIR / 'enrollment_db.json'\n",
        "MANIFEST_JSON = METADATA_DIR / 'manifest.json'\n",
        "\n",
        "for p in [DATA_RAW, DATA_PROCESSED, FAMILIAR_DIR, STRANGER_DIR, METADATA_DIR]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def read_wav_mono(path, target_sr=16000):\n",
        "    audio, sr = sf.read(str(path))\n",
        "    if audio.ndim > 1:\n",
        "        audio = np.mean(audio, axis=1)\n",
        "    if sr != target_sr:\n",
        "        audio = resample_poly(audio, target_sr, sr)\n",
        "    return audio.astype(np.float32), target_sr\n",
        "\n",
        "def write_wav(path, audio, sr=16000):\n",
        "    sf.write(str(path), audio, sr, subtype='PCM_16')\n",
        "\n",
        "class Frame:\n",
        "    def __init__(self, bytes_, timestamp, duration):\n",
        "        self.bytes = bytes_\n",
        "        self.timestamp = timestamp\n",
        "        self.duration = duration\n",
        "\n",
        "def frame_generator(frame_ms, audio, sr):\n",
        "    n = int(sr * frame_ms/1000)\n",
        "    timestamp = 0.0\n",
        "    duration = n/sr\n",
        "    int16_audio = (audio * 32768).astype('int16')\n",
        "    for i in range(0, len(audio)-n, n):\n",
        "        chunk = int16_audio[i:i+n]\n",
        "        yield Frame(chunk.tobytes(), timestamp, duration)\n",
        "        timestamp += duration\n",
        "\n",
        "def vad_segment(in_path, out_folder, aggressiveness=2):\n",
        "    audio, sr = read_wav_mono(in_path)\n",
        "    vad = webrtcvad.Vad(aggressiveness)\n",
        "    frames = list(frame_generator(30, audio, sr))\n",
        "    os.makedirs(out_folder, exist_ok=True)\n",
        "    saved = []\n",
        "    for i, fr in enumerate(frames):\n",
        "        if vad.is_speech(fr.bytes, sr):\n",
        "            arr = np.frombuffer(fr.bytes, dtype='int16').astype('float32')/32768.0\n",
        "            op = Path(out_folder)/f\"seg_{i}.wav\"\n",
        "            write_wav(op, arr, sr)\n",
        "            saved.append(str(op))\n",
        "    return saved\n",
        "\n",
        "print(\"✅ Notebook initialized — ready for VAD segmentation!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
