{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayush-1204/Speaker_Recognition_System/blob/main/notebooks/02_feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9ORrEqyUyf1"
      },
      "source": [
        "# Notebook 02 — Feature Extraction (YAMNet embeddings)\n",
        "\n",
        "This notebook extracts embeddings using **YAMNet** (TensorFlow Hub) for every processed WAV under `data/processed/` and saves them into `data/features/` along with a manifest.\n",
        "\n",
        "**Outputs**:\n",
        "- Embeddings saved to `data/features/*.npy`\n",
        "- Manifest saved to `metadata/features_manifest.json`\n"
      ],
      "id": "N9ORrEqyUyf1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9pXIEJzUyf2"
      },
      "execution_count": 1,
      "outputs": [],
      "source": [
        "!pip install --quiet tensorflow tensorflow_hub soundfile librosa numpy\n"
      ],
      "id": "y9pXIEJzUyf2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsbdeS6kUyf3",
        "outputId": "466c6c8b-9940-428a-84c0-79cc2f5d55c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed dir: data/processed\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "ROOT = Path('.')\n",
        "PROCESSED = ROOT / 'data' / 'processed'\n",
        "FEATURES = ROOT / 'data' / 'features'\n",
        "METADATA_DIR = ROOT / 'metadata'\n",
        "FEATURES_MANIFEST = METADATA_DIR / 'features_manifest.json'\n",
        "\n",
        "for p in [FEATURES, METADATA_DIR]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "print('Processed dir:', PROCESSED)\n"
      ],
      "id": "dsbdeS6kUyf3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd-LMyUfUyf3",
        "outputId": "aa19de13-251a-408f-ad88-18b0f7af91c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 files\n"
          ]
        }
      ],
      "source": [
        "def load_wav(path, target_sr=16000):\n",
        "    audio, sr = sf.read(str(path))\n",
        "    if audio.ndim > 1:\n",
        "        audio = audio.mean(axis=1)\n",
        "    if sr != target_sr:\n",
        "        audio = librosa.resample(audio.astype('float32'), orig_sr=sr, target_sr=target_sr)\n",
        "    return audio.astype('float32'), target_sr\n",
        "\n",
        "wav_list = list(PROCESSED.rglob('*.wav'))\n",
        "print('Found', len(wav_list), 'files')\n"
      ],
      "id": "bd-LMyUfUyf3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KWYr15uUyf4",
        "outputId": "0b9bdc79-99fb-4f60-a2c6-c143c6ac878f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YAMNet loaded\n"
          ]
        }
      ],
      "source": [
        "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
        "yamnet = hub.load(yamnet_model_handle)\n",
        "print('YAMNet loaded')\n",
        "\n",
        "def extract_emb(waveform):\n",
        "    wf = tf.convert_to_tensor(waveform, dtype=tf.float32)\n",
        "    _, embeddings, _ = yamnet(wf)\n",
        "    return embeddings.numpy().mean(axis=0)\n"
      ],
      "id": "7KWYr15uUyf4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxLNLh4YUyf4",
        "outputId": "547e29dd-a54c-4f4d-bbf8-faa8fd282ad2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Done — Manifest saved: metadata/features_manifest.json\n"
          ]
        }
      ],
      "source": [
        "manifest = []\n",
        "for wav_path in wav_list:\n",
        "    rel = wav_path.relative_to(PROCESSED)\n",
        "    audio, sr = load_wav(wav_path)\n",
        "    emb = extract_emb(audio)\n",
        "    feat_path = FEATURES / (str(rel).replace('/', '_') + '.npy')\n",
        "    np.save(str(feat_path), emb)\n",
        "    parts = rel.parts\n",
        "    label = 'familiar' if parts[0]=='familiar' else 'stranger'\n",
        "    speaker_id = parts[1] if label=='familiar' else None\n",
        "    manifest.append({'wav': str(wav_path), 'emb': str(feat_path), 'label': label, 'speaker_id': speaker_id})\n",
        "\n",
        "with open(FEATURES_MANIFEST, 'w') as f:\n",
        "    json.dump(manifest, f, indent=2)\n",
        "print('✅ Done — Manifest saved:', FEATURES_MANIFEST)\n"
      ],
      "id": "jxLNLh4YUyf4"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
