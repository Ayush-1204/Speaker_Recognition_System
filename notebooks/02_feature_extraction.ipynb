{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 02 \u2014 Feature Extraction (YAMNet embeddings)\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ayush-1204/Speaker_Recognition_System/blob/main/notebooks/02_feature_extraction.ipynb)\n",
        "\n",
        "This notebook extracts embeddings using **YAMNet** (TensorFlow Hub) for every processed WAV under `data/processed/` and saves them into `data/features/` along with a manifest.\n",
        "\n",
        "**Outputs**:\n",
        "- Embeddings saved to `data/features/*.npy`\n",
        "- Manifest saved to `metadata/features_manifest.json`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "!pip install --quiet tensorflow tensorflow_hub soundfile librosa numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "ROOT = Path('.')\n",
        "PROCESSED = ROOT / 'data' / 'processed'\n",
        "FEATURES = ROOT / 'data' / 'features'\n",
        "METADATA_DIR = ROOT / 'metadata'\n",
        "FEATURES_MANIFEST = METADATA_DIR / 'features_manifest.json'\n",
        "\n",
        "for p in [FEATURES, METADATA_DIR]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "print('Processed dir:', PROCESSED)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def load_wav(path, target_sr=16000):\n",
        "    audio, sr = sf.read(str(path))\n",
        "    if audio.ndim > 1:\n",
        "        audio = audio.mean(axis=1)\n",
        "    if sr != target_sr:\n",
        "        audio = librosa.resample(audio.astype('float32'), orig_sr=sr, target_sr=target_sr)\n",
        "    return audio.astype('float32'), target_sr\n",
        "\n",
        "wav_list = list(PROCESSED.rglob('*.wav'))\n",
        "print('Found', len(wav_list), 'files')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
        "yamnet = hub.load(yamnet_model_handle)\n",
        "print('YAMNet loaded')\n",
        "\n",
        "def extract_emb(waveform):\n",
        "    wf = tf.convert_to_tensor(waveform, dtype=tf.float32)\n",
        "    _, embeddings, _ = yamnet(wf)\n",
        "    return embeddings.numpy().mean(axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "manifest = []\n",
        "for wav_path in wav_list:\n",
        "    rel = wav_path.relative_to(PROCESSED)\n",
        "    audio, sr = load_wav(wav_path)\n",
        "    emb = extract_emb(audio)\n",
        "    feat_path = FEATURES / (str(rel).replace('/', '_') + '.npy')\n",
        "    np.save(str(feat_path), emb)\n",
        "    parts = rel.parts\n",
        "    label = 'familiar' if parts[0]=='familiar' else 'stranger'\n",
        "    speaker_id = parts[1] if label=='familiar' else None\n",
        "    manifest.append({'wav': str(wav_path), 'emb': str(feat_path), 'label': label, 'speaker_id': speaker_id})\n",
        "\n",
        "with open(FEATURES_MANIFEST, 'w') as f:\n",
        "    json.dump(manifest, f, indent=2)\n",
        "print('\u2705 Done \u2014 Manifest saved:', FEATURES_MANIFEST)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
